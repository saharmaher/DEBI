{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6mqvisycY6m-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, regularizers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the dataset\n",
        "def load_and_preprocess_data(file_path):\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    # Drop the 'id' column\n",
        "    data = data.drop(columns=['id'])\n",
        "\n",
        "    # Encode the target variable ('species') using LabelEncoder\n",
        "    label_encoder = LabelEncoder()\n",
        "    data['species'] = label_encoder.fit_transform(data['species'])\n",
        "\n",
        "    # Separate features and target\n",
        "    X = data.drop(columns=['species'])\n",
        "    y = data['species']\n",
        "\n",
        "    # Normalize the features\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    # Split the data into training and validation sets (80% train, 20% validation)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    return X_train, X_val, y_train, y_val, label_encoder\n"
      ],
      "metadata": {
        "id": "RvgZh82zY_ki"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_mlp_model(input_dim, hidden_size, dropout_rate, l2_reg):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "        layers.Dense(hidden_size, activation='tanh',\n",
        "                     kernel_regularizer=regularizers.l2(l2_reg)),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Dense(len(set(y_train)), activation='softmax')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "0Aw4gFkiZvzx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train the model and evaluate performance\n",
        "def train_and_evaluate_model(X_train, X_val, y_train, y_val, hidden_size, dropout_rate, l2_reg, optimizer, learning_rate, batch_size, epochs):\n",
        "    # Build the model\n",
        "    model = build_mlp_model(input_dim=X_train.shape[1],\n",
        "                            hidden_size=hidden_size,\n",
        "                            dropout_rate=dropout_rate,\n",
        "                            l2_reg=l2_reg)\n",
        "\n",
        "    # Compile the model\n",
        "    opt = optimizer(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        validation_data=(X_val, y_val),\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        verbose=1)\n",
        "\n",
        "    # Evaluate the model\n",
        "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "    return history, val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "JT4SA0WGZ2ix"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/train.csv'\n",
        "# Load and preprocess data\n",
        "X_train, X_val, y_train, y_val, label_encoder = load_and_preprocess_data(file_path)"
      ],
      "metadata": {
        "id": "QrZCG_JLarD5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nQtMrQWbatjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    # Example hyperparameters\n",
        "    hidden_size = 64\n",
        "    dropout_rate = 0.5\n",
        "    l2_reg = 0.01\n",
        "    optimizer = optimizers.Adam\n",
        "    learning_rate = 0.001\n",
        "    batch_size = 32\n",
        "    epochs = 20\n",
        "\n",
        "    # Train and evaluate the model\n",
        "    history, val_loss, val_accuracy = train_and_evaluate_model(\n",
        "        X_train, X_val, y_train, y_val,\n",
        "        hidden_size=hidden_size,\n",
        "        dropout_rate=dropout_rate,\n",
        "        l2_reg=l2_reg,\n",
        "        optimizer=optimizer,\n",
        "        learning_rate=learning_rate,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHoHCLExaEyh",
        "outputId": "d05e31a9-ac81-43d5-f08f-15e9ac876c29"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0106 - loss: 5.6480 - val_accuracy: 0.0909 - val_loss: 5.0080\n",
            "Epoch 2/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0667 - loss: 5.0217 - val_accuracy: 0.2172 - val_loss: 4.5251\n",
            "Epoch 3/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2065 - loss: 4.4521 - val_accuracy: 0.3586 - val_loss: 4.1372\n",
            "Epoch 4/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3604 - loss: 3.9078 - val_accuracy: 0.4444 - val_loss: 3.8044\n",
            "Epoch 5/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4324 - loss: 3.6171 - val_accuracy: 0.5707 - val_loss: 3.4994\n",
            "Epoch 6/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5438 - loss: 3.2665 - val_accuracy: 0.6414 - val_loss: 3.2274\n",
            "Epoch 7/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6022 - loss: 3.0099 - val_accuracy: 0.7121 - val_loss: 2.9959\n",
            "Epoch 8/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6891 - loss: 2.7678 - val_accuracy: 0.7424 - val_loss: 2.7693\n",
            "Epoch 9/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7386 - loss: 2.5431 - val_accuracy: 0.7980 - val_loss: 2.5641\n",
            "Epoch 10/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7841 - loss: 2.3519 - val_accuracy: 0.8434 - val_loss: 2.3975\n",
            "Epoch 11/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7846 - loss: 2.2449 - val_accuracy: 0.8485 - val_loss: 2.2379\n",
            "Epoch 12/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8344 - loss: 2.0555 - val_accuracy: 0.8838 - val_loss: 2.0757\n",
            "Epoch 13/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8686 - loss: 1.8930 - val_accuracy: 0.8939 - val_loss: 1.9420\n",
            "Epoch 14/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8790 - loss: 1.8155 - val_accuracy: 0.9040 - val_loss: 1.8231\n",
            "Epoch 15/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9014 - loss: 1.6989 - val_accuracy: 0.9141 - val_loss: 1.7118\n",
            "Epoch 16/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9115 - loss: 1.6003 - val_accuracy: 0.9242 - val_loss: 1.6062\n",
            "Epoch 17/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9404 - loss: 1.5058 - val_accuracy: 0.9242 - val_loss: 1.5237\n",
            "Epoch 18/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9412 - loss: 1.3700 - val_accuracy: 0.9343 - val_loss: 1.4428\n",
            "Epoch 19/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9328 - loss: 1.3569 - val_accuracy: 0.9495 - val_loss: 1.3583\n",
            "Epoch 20/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9505 - loss: 1.2603 - val_accuracy: 0.9596 - val_loss: 1.2988\n",
            "Validation Loss: 1.2988, Validation Accuracy: 0.9596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6193rHNbavtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bEqTqGr0aSsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1VxvpUxoZo9C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}